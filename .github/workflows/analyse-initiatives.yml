name: analyse-initiatives

on:
  issues:
    types: [opened, edited]

permissions:
  contents: write
  issues: write
  pull-requests: write

jobs:
  analyse-initiative:
    if: contains(github.event.issue.labels.*.name, 'type:initiative')
    runs-on: ubuntu-latest
    
    steps:
      - name: checkout repository
        uses: actions/checkout@v4
        
      - name: setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          
      - name: install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests
          
      - name: parse initiative issue
        id: parse
        run: |
          python - <<'EOF'
          import os
          import re
          import json
          
          body = os.environ['ISSUE_BODY']
          title = os.environ['ISSUE_TITLE']
          
          def extract_field(field_name, multiline=False):
              pattern = rf"###\s*{field_name}\s*\n\s*([^#]*?)(?=\n###|\n\n|\Z)"
              match = re.search(pattern, body, re.IGNORECASE | re.DOTALL)
              if not match:
                  return [] if multiline else ""
              
              content = match.group(1).strip()
              if multiline:
                  lines = [line.strip() for line in content.splitlines() if line.strip()]
                  return [re.sub(r"^[-*]\s*", "", line) for line in lines]
              return content
          
          # Extract all fields
          initiative_data = {
              "title": title,
              "archetype": extract_field("archetype"),
              "domain": extract_field("domain"),
              "initiativeTitle": extract_field("initiativeTitle"),
              "purpose": extract_field("purpose"),
              "scope": extract_field("scope"),
              "capabilityAreas": extract_field("capabilityAreas"),
              "deliverables": extract_field("deliverables"),
              "successIndicators": extract_field("successIndicators"),
              "constraints": extract_field("constraints"),
              "dependencies": extract_field("dependencies"),
              "developmentMethodology": extract_field("developmentMethodology"),
              "nonNegotiables": extract_field("nonNegotiables"),
              "reusePriority": extract_field("reusePriority"),
              "securityPosture": extract_field("securityPosture"),
              "humanInTheLoop": extract_field("humanInTheLoop"),
              "testStrategy": extract_field("testStrategy"),
              "rolloutPlan": extract_field("rolloutPlan"),
              "lessonsFromPastInitiatives": extract_field("lessonsFromPastInitiatives"),
              "outcomeStatus": extract_field("outcomeStatus"),
              "postmortem": extract_field("postmortem")
          }
          
          # Save parsed data
          with open("initiative_data.json", "w") as f:
              json.dump(initiative_data, f, indent=2)
          
          print(f"Parsed initiative: {initiative_data.get('initiativeTitle', 'Unknown')}")
          EOF
        env:
          ISSUE_BODY: ${{ github.event.issue.body }}
          ISSUE_TITLE: ${{ github.event.issue.title }}
          
      - name: build or update history index
        run: |
          echo "ðŸ” Building/updating initiative history index..."
          python scripts/build_history.py
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: generate lessons from similar initiatives
        run: |
          echo "ðŸŽ“ Generating lessons from similar initiatives..."
          python - <<'EOF'
          import json
          import sys
          import os
          
          # Add scripts directory to path
          sys.path.insert(0, 'scripts')
          
          try:
              from generate_lessons import InitiativeLessonsGenerator
              
              # Load initiative data
              with open("initiative_data.json", "r") as f:
                  initiative_data = json.load(f)
              
              # Generate lessons
              generator = InitiativeLessonsGenerator()
              lessons_result = generator.generate_lessons(initiative_data)
              
              # Save lessons data
              with open("lessons_data.json", "w") as f:
                  json.dump(lessons_result, f, indent=2)
              
              print(f"Generated lessons with {lessons_result.get('confidence', 0):.1f}% confidence")
              
          except Exception as e:
              print(f"Error generating lessons: {e}")
              # Create empty lessons file to prevent downstream failures
              with open("lessons_data.json", "w") as f:
                  json.dump({"error": str(e), "confidence": 0, "similar_count": 0}, f)
          EOF
          
      - name: assess initiative readiness
        run: |
          echo "ðŸ“Š Assessing initiative readiness..."
          python - <<'EOF'
          import json
          import sys
          
          # Add scripts directory to path
          sys.path.insert(0, 'scripts')
          
          try:
              from label_readiness import InitiativeReadinessLabeller
              
              # Load data
              with open("initiative_data.json", "r") as f:
                  initiative_data = json.load(f)
              
              with open("lessons_data.json", "r") as f:
                  lessons_data = json.load(f)
              
              # Assess readiness
              labeller = InitiativeReadinessLabeller()
              assessment = labeller.assess_readiness(initiative_data, lessons_data)
              
              # Save assessment
              with open("readiness_assessment.json", "w") as f:
                  json.dump(assessment, f, indent=2)
              
              print(f"Readiness assessment: {assessment['readiness_score']:.1f}/100 ({assessment['readiness_level']})")
              
          except Exception as e:
              print(f"Error assessing readiness: {e}")
              # Create minimal assessment to prevent failures
              assessment = {
                  "readiness_score": 50.0,
                  "readiness_level": "needs-work",
                  "recommendations": [f"Assessment failed: {str(e)}"],
                  "labels_to_add": ["readiness:needs-work"],
                  "labels_to_remove": []
              }
              with open("readiness_assessment.json", "w") as f:
                  json.dump(assessment, f, indent=2)
          EOF
          
      - name: post lessons comment
        run: |
          echo "ðŸ’¬ Posting lessons comment..."
          python - <<'EOF'
          import json
          import sys
          import os
          
          # Add scripts directory to path
          sys.path.insert(0, 'scripts')
          
          try:
              from post_comment import InitiativeCommentPoster
              
              # Load lessons data
              with open("lessons_data.json", "r") as f:
                  lessons_data = json.load(f)
              
              # Post comment
              poster = InitiativeCommentPoster()
              success = poster.post_lessons_comment(
                  repo_owner="SPECTRADataSolutions",
                  repo_name=".github", 
                  issue_number=int(os.environ['ISSUE_NUMBER']),
                  lessons_data=lessons_data
              )
              
              if success:
                  print("âœ… Posted lessons comment")
              else:
                  print("âŒ Failed to post comment")
                  
          except Exception as e:
              print(f"Error posting comment: {e}")
          EOF
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          ISSUE_NUMBER: ${{ github.event.issue.number }}
          
      - name: apply readiness labels
        run: |
          echo "ðŸ·ï¸ Applying readiness labels..."
          python - <<'EOF'
          import json
          import sys
          import os
          
          # Add scripts directory to path  
          sys.path.insert(0, 'scripts')
          
          try:
              from label_readiness import InitiativeReadinessLabeller
              
              # Load assessment data
              with open("readiness_assessment.json", "r") as f:
                  assessment = json.load(f)
              
              # Apply labels
              labeller = InitiativeReadinessLabeller()
              success = labeller.apply_readiness_labels(
                  repo_owner="SPECTRADataSolutions",
                  repo_name=".github",
                  issue_number=int(os.environ['ISSUE_NUMBER']),
                  labels_to_add=assessment['labels_to_add'],
                  labels_to_remove=assessment['labels_to_remove']
              )
              
              if success:
                  print("âœ… Applied readiness labels")
              else:
                  print("âŒ Failed to apply labels")
                  
          except Exception as e:
              print(f"Error applying labels: {e}")
          EOF
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          ISSUE_NUMBER: ${{ github.event.issue.number }}
          
      - name: update initiative history
        if: success()
        run: |
          # Commit updated history file if it was modified
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          if [ -f "analytics/initiatives-history.jsonl" ]; then
            git add analytics/initiatives-history.jsonl
            
            if ! git diff --cached --quiet; then
              git commit -m "chore(analytics): update initiative history index"
              git push
            else
              echo "No changes to history index"
            fi
          fi
          
      - name: create analysis summary
        if: always()
        run: |
          echo "## ðŸŽ“ Initiative Analysis Summary" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "lessons_data.json" ]; then
            confidence=$(jq -r '.confidence // 0' lessons_data.json)
            similar_count=$(jq -r '.similar_count // 0' lessons_data.json)
            echo "**Lessons Analysis:** ${confidence}% confidence from ${similar_count} similar initiatives" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -f "readiness_assessment.json" ]; then
            score=$(jq -r '.readiness_score // 0' readiness_assessment.json)
            level=$(jq -r '.readiness_level // "unknown"' readiness_assessment.json)
            echo "**Readiness Score:** ${score}/100 (${level})" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… **Actions Completed:**" >> $GITHUB_STEP_SUMMARY
          echo "- History index updated with past initiatives" >> $GITHUB_STEP_SUMMARY
          echo "- Lessons extracted from similar initiatives" >> $GITHUB_STEP_SUMMARY  
          echo "- Readiness assessment performed" >> $GITHUB_STEP_SUMMARY
          echo "- Lessons comment posted" >> $GITHUB_STEP_SUMMARY
          echo "- Readiness labels applied" >> $GITHUB_STEP_SUMMARY
          
      - name: upload analysis artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: initiative-analysis-${{ github.event.issue.number }}
          path: |
            initiative_data.json
            lessons_data.json
            readiness_assessment.json
            analytics/initiatives-history.jsonl
          retention-days: 90